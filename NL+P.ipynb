{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = \"Scientists know many things about the Sun. They know how old it is. The Sun is more than 4½ billion years old. They also know the Sun’s size. The Sun may seem small, but that is because it is so far away. It is about 93 million miles (150 million kilometers) away from the Earth. The Sun is so large that the diameter of the Sun is  109 times the Earth’s diameter. The Sun also weighs as much as 333,000 Earths. The Sun is the center of our Solar System. Besides the Sun, the Solar System is made up of the planets,  moons, asteroid belt, comets, meteors, and other objects.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "words = nltk.pos_tag(nltk.word_tokenize(S))\n",
    "words_stop = [w for w in words if w not in nltk.corpus.stopwords.words()]\n",
    "print len(words_stop)\n",
    "S2 = \"Vijay Bhatkar is the chancellor of Nalanda University. He lives in Rohini Delhi.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Tokenization\n",
    "2. Pos Tagging\n",
    "3. NER (Named Entity Recognition) : \n",
    "    a. Split the sentences.\n",
    "    b. For the sentence use the ne_chunk using its tags\n",
    "    c. return the pos_tags, named_entities\n",
    "\"\"\"\n",
    "def preprocess(S):\n",
    "    sentences = S.split('.')\n",
    "    pos_tags = []\n",
    "    named_entity = []\n",
    "    for sentence in sentences:\n",
    "        pos_tags.append(nltk.pos_tag(nltk.word_tokenize(sentence)))\n",
    "        parse_tree = nltk.ne_chunk(nltk.tag.pos_tag(sentence.split()), binary=True)\n",
    "        for tree in parse_tree.subtrees():\n",
    "            if tree.label()=='NE':\n",
    "                entity = \"\"\n",
    "                for t in tree:\n",
    "                    entity+=t[0]+\" \"\n",
    "                named_entity.append(entity[:-1])\n",
    "        \n",
    "    return (pos_tags, named_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags, named_entities = preprocess(S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vijay Bhatkar', 'Nalanda University', 'Rohini Delhi']\n"
     ]
    }
   ],
   "source": [
    "print named_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp=en_core_web_sm.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'Apple', 0, 5, u'ORG')\n",
      "(u'U.K.', 27, 31, u'GPE')\n",
      "(u'$1 billion', 44, 54, u'MONEY')\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               jumps                        \n",
      "  _______________|__________________         \n",
      " |       fox                       over     \n",
      " |    ____|______________           |        \n",
      " |   |    |      |     brown       dog      \n",
      " |   |    |      |       |       ___|____    \n",
      " .  The quick cunning slightly the      lazy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import Tree\n",
    "doc=nlp(u'The quick cunning slightly brown fox jumps over the lazy dog.')\n",
    "\n",
    "[to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_nltk_tree(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
    "    else:\n",
    "        return node.orth_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
